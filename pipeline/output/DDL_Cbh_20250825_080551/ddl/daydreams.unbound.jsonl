{"pair": ["Singular Learning Theory (SLT)", "Singular Learning Theory seminar | metauni"], "paper_concept": "Singular Learning Theory (SLT)", "corpus_concept": "Singular Learning Theory seminar | metauni", "author": "Unknown", "year": 2020, "title": "Singular Learning Theory seminar | metauni", "doc_id": "8ce21bced6af2eb2dddd21960b3d516670167ca0ad295ad09ae72410b60d48a3", "sampling_score": 0.35847775175644025, "hypothesis": "CLAIM: The abrupt performance jumps observed during language model scaling are manifestations of phase transitions predicted by Singular Learning Theory (SLT). MECHANISM: According to the theory, as parameters cross critical values the loss landscape changes topology, causing sudden increases in representational capacity that align with emergent linguistic abilities. TEST: Conduct an ablation control where training is halted before a suspected transition point and then resumed after injecting a small perturbation to weight magnitudes; compare validation perplexity on a hold\u2011out set. SIGNALS: A rapid drop in perplexity and emergence of higher\u2011order syntactic constructions after the perturbation would support the claim, whereas smooth monotonic improvement or no change would refute it; additionally, tracking the Fisher information spectrum should reveal a sharp rise in eigenvalue density at the same step, providing an independent quantitative indicator.", "paper_anchor": "Singular Learning Theory (SLT)", "test": {"type": "ablation_control", "dataset_or_component": "WikiText-103 validation set for a GPT\u2011like language model", "manipulation": "pause training before predicted transition, add small Gaussian noise to weights, then resume", "metric": "validation perplexity", "expected_direction": "decrease", "success_threshold": 0.02, "timeframe_days": 7}, "critic": {"novelty": 0.81, "coherence": 0.905, "usefulness": 0.855, "binding": 1.0, "overall_score": 0.69255, "diagnostics": {"hard": true, "soft": 0.06, "binding_score": 1.0}}, "evidence": [], "tier": "unbound", "unbound_reason": "No quotes", "_parquet_files_loaded": 1}
{"pair": ["Phase Transitions in Model Training", "How might we align transformative AI if it\u2019s developed very soon? - Effective Altruism forum viewer"], "paper_concept": "Phase Transitions in Model Training", "corpus_concept": "How might we align transformative AI if it\u2019s developed very soon? - Effective Altruism forum viewer", "author": "Unknown", "year": 2020, "title": "How might we align transformative AI if it\u2019s developed very soon? - Effective Altruism forum viewer", "doc_id": "b37d2c737bda30727494cc60ba6538552115fcfcff2db1baf9b5d6ff77d9e8f6", "sampling_score": 0.47563998190863865, "hypothesis": "CLAIM: Early alignment interventions that target the rapid transition zones identified by Phase Transitions in Model Training will reduce the probability of emergent reward\u2011maximizing disempowerment behaviors in large language models. MECHANISM: The hypothesis rests on the idea that during these narrow transition phases the model\u2019s internal representations are highly plastic, so modest regularization or value\u2011learning adjustments can steer the trajectory before it settles into a stable, potentially misaligned regime. TEST: Conduct an ablation control where a standard training run is compared to a run that inserts a calibrated alignment loss only during epochs identified as transition points using gradient norm spikes. SIGNALS: A significant drop in downstream power\u2011seeking test prompts (e.g., reduced instrumental subgoal activation) without harming benchmark performance would support the claim; unchanged or worsened safety metrics would refute it.", "paper_anchor": "Phase Transitions in Model Training", "test": {"type": "ablation_control", "dataset_or_component": "large language model training epochs with gradient norm spike detection", "manipulation": "add alignment loss only during detected transition epochs", "metric": "frequency of power\u2011seeking test prompts per evaluation batch", "expected_direction": "decrease", "success_threshold": 0.1, "timeframe_days": 30}, "critic": {"novelty": 0.75, "coherence": 0.9, "usefulness": 0.85, "binding": 1.0, "overall_score": 0.6375, "diagnostics": {"hard": true, "soft": 0.07, "binding_score": 1.0}}, "evidence": [], "tier": "unbound", "unbound_reason": "No quotes"}
